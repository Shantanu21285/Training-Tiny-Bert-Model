{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15279e9-ab33-404b-bb86-49e3a79edabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip --version\n",
    "\n",
    "# To install pytorch -------------------------------------------------------------------------------------\n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "# To install Tensorflow ----------------------------------------------------------------------------------\n",
    "# Requires the latest pip\n",
    "!pip install --upgrade pip\n",
    "\n",
    "# Current stable release for CPU and GPU\n",
    "!pip install tensorflow\n",
    "\n",
    "# To install Flax ----------------------------------------------------------------------------------------\n",
    "!pip install flax\n",
    "\n",
    "# or to install the latest version of Flax:\n",
    "!pip install --upgrade git+https://github.com/google/flax.git\n",
    "\n",
    "# Set up transformers\n",
    "!pip install git+https://github.com/huggingface/transformers\n",
    "\n",
    "# Check if installed\n",
    "!python -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('I love you'))\"\n",
    "\n",
    "!pip install transformers[torch]\n",
    "\n",
    "!pip install accelerate -U\n",
    "\n",
    "!pip install -q datasets peft evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3015aa02-cedc-46ea-9f31-49b48ae4ab50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import (AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding, TrainingArguments, Trainer )\n",
    "from peft import ( get_peft_config, get_peft_model, get_peft_model_state_dict, set_peft_model_state_dict, PeftType,PromptEncoderConfig,PeftModelForSequenceClassification)\n",
    "from peft import PromptEmbedding, PromptTuningConfig\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "from transformers import AdamW\n",
    "import torch\n",
    "import numpy as np\n",
    "from peft import LoraModel, LoraConfig\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"sst2\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\", num_labels=2) # as output 0 or 1\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-tiny\", padding_side = \"right\")\n",
    "model = model.to('cuda')\n",
    "# optimizer = AdamW(model.parameters(), lr= 0.005, eps = 1e-8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "418dd3b2-4847-4de5-b804-b0c1294ea7c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting loralib\n",
      "  Obtaining dependency information for loralib from https://files.pythonhosted.org/packages/f1/e7/a4362bf791bca17d2d91e7c69483185ab03d5aa05dd10391eff2e179a685/loralib-0.1.2-py3-none-any.whl.metadata\n",
      "  Downloading loralib-0.1.2-py3-none-any.whl.metadata (15 kB)\n",
      "Downloading loralib-0.1.2-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: loralib\n",
      "Successfully installed loralib-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install loralib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acc76686-66b8-4035-a0ab-55946a5c13bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "s3fs 2023.4.0 requires fsspec==2023.4.0, but you have fsspec 2023.12.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q git+https://github.com/huggingface/peft.git git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "810cd199-2a6a-4568-a33d-bb9604e51b40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bert\n",
      "bert.embeddings\n",
      "bert.embeddings.word_embeddings\n",
      "bert.embeddings.position_embeddings\n",
      "bert.embeddings.token_type_embeddings\n",
      "bert.embeddings.LayerNorm\n",
      "bert.embeddings.dropout\n",
      "bert.encoder\n",
      "bert.encoder.layer\n",
      "bert.encoder.layer.0\n",
      "bert.encoder.layer.0.attention\n",
      "bert.encoder.layer.0.attention.self\n",
      "bert.encoder.layer.0.attention.self.query\n",
      "bert.encoder.layer.0.attention.self.key\n",
      "bert.encoder.layer.0.attention.self.value\n",
      "bert.encoder.layer.0.attention.self.dropout\n",
      "bert.encoder.layer.0.attention.output\n",
      "bert.encoder.layer.0.attention.output.dense\n",
      "bert.encoder.layer.0.attention.output.LayerNorm\n",
      "bert.encoder.layer.0.attention.output.dropout\n",
      "bert.encoder.layer.0.intermediate\n",
      "bert.encoder.layer.0.intermediate.dense\n",
      "bert.encoder.layer.0.intermediate.intermediate_act_fn\n",
      "bert.encoder.layer.0.output\n",
      "bert.encoder.layer.0.output.dense\n",
      "bert.encoder.layer.0.output.LayerNorm\n",
      "bert.encoder.layer.0.output.dropout\n",
      "bert.encoder.layer.1\n",
      "bert.encoder.layer.1.attention\n",
      "bert.encoder.layer.1.attention.self\n",
      "bert.encoder.layer.1.attention.self.query\n",
      "bert.encoder.layer.1.attention.self.key\n",
      "bert.encoder.layer.1.attention.self.value\n",
      "bert.encoder.layer.1.attention.self.dropout\n",
      "bert.encoder.layer.1.attention.output\n",
      "bert.encoder.layer.1.attention.output.dense\n",
      "bert.encoder.layer.1.attention.output.LayerNorm\n",
      "bert.encoder.layer.1.attention.output.dropout\n",
      "bert.encoder.layer.1.intermediate\n",
      "bert.encoder.layer.1.intermediate.dense\n",
      "bert.encoder.layer.1.intermediate.intermediate_act_fn\n",
      "bert.encoder.layer.1.output\n",
      "bert.encoder.layer.1.output.dense\n",
      "bert.encoder.layer.1.output.LayerNorm\n",
      "bert.encoder.layer.1.output.dropout\n",
      "bert.pooler\n",
      "bert.pooler.dense\n",
      "bert.pooler.activation\n",
      "dropout\n",
      "classifier\n"
     ]
    }
   ],
   "source": [
    "for name, modules in model.named_modules():\n",
    "  print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c32916a-8815-4fec-88da-92aeef49cadf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 4394370\n",
      "trainable_param 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shantanu\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "config = LoraConfig(\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"query\", \"value\"],\n",
    "    lora_dropout=0.01,\n",
    ")\n",
    "\n",
    "model = LoraModel(model, config, \"default\")\n",
    "\n",
    "total_params = 0\n",
    "trainable_params = 0\n",
    "\n",
    "# trainable_layers = [model.prompt_encoder, model.classifier]\n",
    "for p in model.parameters():\n",
    "        p.requires_grad = False\n",
    "        total_params += p.numel()\n",
    "\n",
    "for p in model.classifier.parameters():\n",
    "    p.requires_grad = True\n",
    "        \n",
    "optimizer = AdamW(model.parameters(), lr= 0.005, eps = 1e-8)\n",
    "\n",
    "print(\"total:\",total_params)\n",
    "print(\"trainable_param\",trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04ec1302-8f2f-4f5a-9947-cb92b1e27e69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shantanu\\anaconda3\\envs\\myenv\\lib\\site-packages\\pyarrow\\pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "\n",
    "# Assuming the dataset has a 'train' split, modify this according to your dataset's splits\n",
    "data_split = dataset['train']\n",
    "\n",
    "# Convert the dataset split to a pandas DataFrame for easier splitting\n",
    "df = data_split.to_pandas()\n",
    "\n",
    "# Split the dataset into train and test sets using train_test_split from sklearn\n",
    "# df1, df2 = train_test_split(df, test_size = 0.5, random_state = 42)\n",
    "train_df, test_df = train_test_split(df , test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the splits back to datasets\n",
    "train_dataset = train_df.reset_index(drop=True)\n",
    "test_dataset = test_df.reset_index(drop=True)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_dataset)\n",
    "test_dataset = Dataset.from_pandas(test_dataset)\n",
    "\n",
    "x_train = list(train_dataset[\"sentence\"])\n",
    "y_train = list(train_dataset[\"label\"])\n",
    "\n",
    "x_test = list(test_dataset[\"sentence\"])\n",
    "y_test = list(test_dataset[\"label\"])\n",
    "\n",
    "X_train_tokenized = tokenizer(x_train, padding=True, truncation=True, max_length=512)\n",
    "# X_val_tokenized = tokenizer(x_validation, padding=True, truncation=True, max_length=512)\n",
    "X_test_tokenized = tokenizer(x_test, padding=True, truncation = True, max_length = 512)\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]).to('cuda') for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx]).to('cuda')\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])\n",
    "\n",
    "train_dataset = Dataset(X_train_tokenized, y_train)\n",
    "# val_dataset = Dataset(X_val_tokenized, y_validation)\n",
    "test_dataset = Dataset(X_test_tokenized, y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 1024, drop_last = True)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size = 1024, drop_last = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31782f4b-69ce-4a98-88ea-97c4f4e5f585",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss 0.6226080197554368\n",
      "accuracy:  0.6748046875\n",
      "ends\n",
      "eval loss 0.6026518207329971\n",
      "accuracy:  0.6843449519230769\n",
      "ends\n",
      "eval loss 0.596383484510275\n",
      "accuracy:  0.6915564903846154\n",
      "ends\n",
      "eval loss 0.5922278945262616\n",
      "accuracy:  0.6917818509615384\n",
      "ends\n",
      "eval loss 0.5907220198557928\n",
      "accuracy:  0.6949368990384616\n",
      "ends\n",
      "eval loss 0.5891422400107751\n",
      "accuracy:  0.6934344951923077\n",
      "ends\n",
      "eval loss 0.5891852516394395\n",
      "accuracy:  0.6967397836538461\n",
      "ends\n",
      "eval loss 0.5867767471533555\n",
      "accuracy:  0.6940354567307693\n",
      "ends\n",
      "eval loss 0.587697079548469\n",
      "accuracy:  0.6881760817307693\n",
      "ends\n",
      "eval loss 0.587439802976755\n",
      "accuracy:  0.6938100961538461\n",
      "ends\n",
      "eval loss 0.5866657403799204\n",
      "accuracy:  0.6887770432692307\n",
      "ends\n",
      "eval loss 0.5864757253573492\n",
      "accuracy:  0.6911057692307693\n",
      "ends\n",
      "eval loss 0.585871146275447\n",
      "accuracy:  0.6962139423076923\n",
      "ends\n",
      "eval loss 0.5859301319489112\n",
      "accuracy:  0.6946364182692307\n",
      "ends\n",
      "eval loss 0.586718696814317\n",
      "accuracy:  0.6935847355769231\n",
      "ends\n",
      "eval loss 0.5855791843854464\n",
      "accuracy:  0.6929837740384616\n",
      "ends\n",
      "eval loss 0.5859927947704608\n",
      "accuracy:  0.6896033653846154\n",
      "ends\n",
      "eval loss 0.5858520865440369\n",
      "accuracy:  0.6981670673076923\n",
      "ends\n",
      "eval loss 0.5855737007581271\n",
      "accuracy:  0.6926832932692307\n",
      "ends\n",
      "eval loss 0.585627977664654\n",
      "accuracy:  0.6916316105769231\n",
      "ends\n",
      "eval loss 0.5858684044617873\n",
      "accuracy:  0.6871995192307693\n",
      "ends\n",
      "eval loss 0.5852093283946698\n",
      "accuracy:  0.6935096153846154\n",
      "ends\n",
      "eval loss 0.5848539334077102\n",
      "accuracy:  0.6911057692307693\n",
      "ends\n",
      "eval loss 0.5844488464868985\n",
      "accuracy:  0.6939603365384616\n",
      "ends\n",
      "eval loss 0.5855052196062528\n",
      "accuracy:  0.6859975961538461\n",
      "ends\n",
      "eval loss 0.5850465572797335\n",
      "accuracy:  0.6868239182692307\n",
      "ends\n",
      "eval loss 0.5845223160890433\n",
      "accuracy:  0.6892277644230769\n",
      "ends\n",
      "eval loss 0.5847578232104962\n",
      "accuracy:  0.6934344951923077\n",
      "ends\n",
      "eval loss 0.5850694500482999\n",
      "accuracy:  0.6859224759615384\n",
      "ends\n",
      "eval loss 0.5846687326064477\n",
      "accuracy:  0.6913311298076923\n",
      "ends\n",
      "eval loss 0.5855656495461097\n",
      "accuracy:  0.6931340144230769\n",
      "ends\n",
      "eval loss 0.5853785230563238\n",
      "accuracy:  0.6864483173076923\n",
      "ends\n",
      "eval loss 0.5848025908836951\n",
      "accuracy:  0.6893780048076923\n",
      "ends\n",
      "eval loss 0.5854529692576482\n",
      "accuracy:  0.6871995192307693\n",
      "ends\n",
      "eval loss 0.5849150556784409\n",
      "accuracy:  0.6898287259615384\n",
      "ends\n",
      "eval loss 0.5847570758599502\n",
      "accuracy:  0.6944861778846154\n",
      "ends\n",
      "eval loss 0.5852783093085656\n",
      "accuracy:  0.6932091346153846\n",
      "ends\n",
      "eval loss 0.5845667811540457\n",
      "accuracy:  0.6890024038461539\n",
      "ends\n",
      "eval loss 0.5858157460506146\n",
      "accuracy:  0.6871995192307693\n",
      "ends\n",
      "eval loss 0.5854188662308913\n",
      "accuracy:  0.6879507211538461\n",
      "ends\n",
      "eval loss 0.5850583956791804\n",
      "accuracy:  0.6889272836538461\n",
      "ends\n",
      "eval loss 0.5850937779133136\n",
      "accuracy:  0.6896033653846154\n",
      "ends\n",
      "eval loss 0.585180415556981\n",
      "accuracy:  0.6901292067307693\n",
      "ends\n",
      "eval loss 0.5873072651716379\n",
      "accuracy:  0.6840444711538461\n",
      "ends\n",
      "eval loss 0.5846461653709412\n",
      "accuracy:  0.6906550480769231\n",
      "ends\n",
      "eval loss 0.5851244926452637\n",
      "accuracy:  0.6915564903846154\n",
      "ends\n",
      "eval loss 0.5848099085000845\n",
      "accuracy:  0.6890775240384616\n",
      "ends\n",
      "eval loss 0.5846437995250409\n",
      "accuracy:  0.6958383413461539\n",
      "ends\n",
      "eval loss 0.5843489536872277\n",
      "accuracy:  0.6944861778846154\n",
      "ends\n",
      "eval loss 0.5846514289195721\n",
      "accuracy:  0.6941105769230769\n",
      "ends\n",
      "eval loss 0.5835984945297241\n",
      "accuracy:  0.6935096153846154\n",
      "ends\n",
      "eval loss 0.5855586574627802\n",
      "accuracy:  0.6900540865384616\n",
      "ends\n",
      "eval loss 0.5851797644908612\n",
      "accuracy:  0.6958383413461539\n",
      "ends\n",
      "eval loss 0.5855631828308105\n",
      "accuracy:  0.6914813701923077\n",
      "ends\n",
      "eval loss 0.5844508317800668\n",
      "accuracy:  0.6919320913461539\n",
      "ends\n",
      "eval loss 0.5845029950141907\n",
      "accuracy:  0.6947866586538461\n",
      "ends\n"
     ]
    }
   ],
   "source": [
    "def accuracy(preds, labels):\n",
    "    return (preds == labels).mean()\n",
    "\n",
    "# define evaluation cycle\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "\n",
    "    loss_arr = []\n",
    "    accuracy_arr = []\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        #batch = tuple(t.to(\"cuda\") for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            input_ids = batch['input_ids']\n",
    "            attention_mask = batch['attention_mask']\n",
    "            labels = batch['labels']\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss, logits = outputs[:2]\n",
    "\n",
    "            log = logits.cpu()\n",
    "            log = log.numpy()\n",
    "\n",
    "            preds = np.argmax(log, axis=1)\n",
    "            labels = batch['labels'].cpu().numpy()\n",
    "\n",
    "            loss_arr.append(loss.item())\n",
    "            accuracy_arr.append(accuracy(preds, labels))\n",
    "\n",
    "    model.train()\n",
    "    return np.mean(loss_arr), np.mean(accuracy_arr)\n",
    "\n",
    "# Training loop\n",
    "optimizer.zero_grad()  # Explicitly zero the gradient buffers\n",
    "\n",
    "for epoch in range(60):  # Number of epochs\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "\n",
    "        # print(f\"input_ids size: {input_ids.size()}\")\n",
    "        # print(f\"attention_mask size: {attention_mask.size()}\")\n",
    "        # print(f\"labels size: {labels.size()}\")\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        # print(outputs)\n",
    "        loss = outputs[0]\n",
    "        # print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        logits = outputs[1]\n",
    "        predictions = torch.argmax(logits, dim = -1)\n",
    "        #metric.add_batch(predictions = predictions, references = batch[\"labels\"])\n",
    "\n",
    "    eval_loss, eval_accuracy = evaluate(model)\n",
    "    print(\"eval loss\",eval_loss)\n",
    "    print(\"accuracy: \",eval_accuracy)\n",
    "    print(\"ends\")\n",
    "    #metric.compute()\n",
    "    #print(metric)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    for batch in test_dataloader:\n",
    "        with torch.no_grad():\n",
    "            input_ids = batch['input_ids']\n",
    "            attention_mask = batch['attention_mask']\n",
    "            labels = batch['labels']\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            # Further validation steps if needed\n",
    "\n",
    "    model.train()  # Set the model back to training mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973490ef-0e3a-45b1-bab6-30004fe7d445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myJupyter",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
