{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2f1b5b5-d15c-409c-b5e2-d39cd21e93b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import (AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding, TrainingArguments, Trainer )\n",
    "from peft import ( get_peft_config, get_peft_model, get_peft_model_state_dict, set_peft_model_state_dict, PeftType,PromptEncoderConfig,PeftModelForSequenceClassification)\n",
    "from peft import PromptEmbedding, PromptTuningConfig\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "from transformers import AdamW\n",
    "import torch\n",
    "import numpy as np\n",
    "from peft import LoraModel, LoraConfig\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"sst2\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\", num_labels=2) # as output 0 or 1\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-tiny\", padding_side = \"right\")\n",
    "model = model.to('cuda')\n",
    "# optimizer = AdamW(model.parameters(), lr= 0.005, eps = 1e-8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1487a53a-899a-45ab-8ffd-37f9a7896d30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 4394370\n",
      "trainable_param 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shantanu\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "config = LoraConfig(\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"query\", \"value\"],\n",
    "    lora_dropout=0.01,\n",
    ")\n",
    "\n",
    "model = LoraModel(model, config, \"default\")\n",
    "\n",
    "total_params = 0\n",
    "trainable_params = 0\n",
    "\n",
    "# trainable_layers = [model.prompt_encoder, model.classifier]\n",
    "for p in model.parameters():\n",
    "        p.requires_grad = False\n",
    "        total_params += p.numel()\n",
    "\n",
    "for p in model.classifier.parameters():\n",
    "    p.requires_grad = True\n",
    "        \n",
    "optimizer = AdamW(model.parameters(), lr= 0.005, eps = 1e-8)\n",
    "\n",
    "print(\"total:\",total_params)\n",
    "print(\"trainable_param\",trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "220826a1-515d-447c-96c4-bae69fe3e5c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shantanu\\anaconda3\\envs\\myenv\\lib\\site-packages\\pyarrow\\pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "\n",
    "# Assuming the dataset has a 'train' split, modify this according to your dataset's splits\n",
    "data_split = dataset['train']\n",
    "\n",
    "# Convert the dataset split to a pandas DataFrame for easier splitting\n",
    "df = data_split.to_pandas()\n",
    "\n",
    "# Split the dataset into train and test sets using train_test_split from sklearn\n",
    "# df1, df2 = train_test_split(df, test_size = 0.5, random_state = 42)\n",
    "train_df, test_df = train_test_split(df , test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the splits back to datasets\n",
    "train_dataset = train_df.reset_index(drop=True)\n",
    "test_dataset = test_df.reset_index(drop=True)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_dataset)\n",
    "test_dataset = Dataset.from_pandas(test_dataset)\n",
    "\n",
    "x_train = list(train_dataset[\"sentence\"])\n",
    "y_train = list(train_dataset[\"label\"])\n",
    "\n",
    "x_test = list(test_dataset[\"sentence\"])\n",
    "y_test = list(test_dataset[\"label\"])\n",
    "\n",
    "X_train_tokenized = tokenizer(x_train, padding=True, truncation=True, max_length=512)\n",
    "# X_val_tokenized = tokenizer(x_validation, padding=True, truncation=True, max_length=512)\n",
    "X_test_tokenized = tokenizer(x_test, padding=True, truncation = True, max_length = 512)\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]).to('cuda') for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx]).to('cuda')\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])\n",
    "\n",
    "train_dataset = Dataset(X_train_tokenized, y_train)\n",
    "# val_dataset = Dataset(X_val_tokenized, y_validation)\n",
    "test_dataset = Dataset(X_test_tokenized, y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 1024, drop_last = True)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size = 1024, drop_last = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cc4d621-0094-41a7-9e5b-73113e09b6b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shantanu\\anaconda3\\envs\\myenv\\lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shantanu\\anaconda3\\envs\\myenv\\lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shantanu\\anaconda3\\envs\\myenv\\lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "12/17/2023 10:33:58:WARNING:Ignoring drop_last as it is not compatible with DPDataLoader.\n"
     ]
    }
   ],
   "source": [
    "import opacus\n",
    "from opacus import PrivacyEngine\n",
    "from opacus.grad_sample import GradSampleModule\n",
    "\n",
    "model.train()\n",
    "privacy_engine = PrivacyEngine()\n",
    "model, optimizer, train_dataloader = privacy_engine.make_private_with_epsilon(\n",
    "    module=model,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=train_dataloader,\n",
    "    target_delta= 1 / len(train_dataloader),\n",
    "    target_epsilon= 8,\n",
    "    epochs= 3,\n",
    "    max_grad_norm = 0.1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032fd588-185f-478e-a753-e79e4d324ead",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shantanu\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "C:\\Users\\shantanu\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1324: UserWarning: Using non-full backward hooks on a Module that does not return a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_output. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not return a \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval loss 1.8672742018332849\n",
      "accuracy:  0.5612980769230769\n",
      "ends\n",
      "eval loss 1.7463044845140898\n",
      "accuracy:  0.5615985576923077\n",
      "ends\n",
      "eval loss 1.3664837250342736\n",
      "accuracy:  0.5799278846153846\n",
      "ends\n",
      "eval loss 1.1875012654524584\n",
      "accuracy:  0.6135817307692307\n",
      "ends\n",
      "eval loss 0.9876563686590928\n",
      "accuracy:  0.6466346153846154\n",
      "ends\n",
      "eval loss 1.035812795162201\n",
      "accuracy:  0.6491887019230769\n",
      "ends\n",
      "eval loss 0.9796004249499395\n",
      "accuracy:  0.6598557692307693\n",
      "ends\n",
      "eval loss 0.9935642389150766\n",
      "accuracy:  0.6613581730769231\n",
      "ends\n",
      "eval loss 0.8927437708928034\n",
      "accuracy:  0.6797626201923077\n",
      "ends\n",
      "eval loss 0.943330549276792\n",
      "accuracy:  0.67578125\n",
      "ends\n",
      "eval loss 0.978574473124284\n",
      "accuracy:  0.6714242788461539\n",
      "ends\n",
      "eval loss 0.9986070898862985\n",
      "accuracy:  0.6702974759615384\n",
      "ends\n",
      "eval loss 0.914651476419889\n",
      "accuracy:  0.6864483173076923\n",
      "ends\n",
      "eval loss 0.9454886408952566\n",
      "accuracy:  0.6832932692307693\n",
      "ends\n",
      "eval loss 0.9461484826528109\n",
      "accuracy:  0.6825420673076923\n",
      "ends\n",
      "eval loss 0.91639571923476\n",
      "accuracy:  0.6878756009615384\n",
      "ends\n",
      "eval loss 0.9616957031763517\n",
      "accuracy:  0.6817908653846154\n",
      "ends\n",
      "eval loss 0.9282488318590018\n",
      "accuracy:  0.6874248798076923\n",
      "ends\n",
      "eval loss 1.0329044919747572\n",
      "accuracy:  0.673828125\n",
      "ends\n",
      "eval loss 0.9404587837365957\n",
      "accuracy:  0.6862229567307693\n",
      "ends\n",
      "eval loss 0.984771884404696\n",
      "accuracy:  0.6805889423076923\n",
      "ends\n",
      "eval loss 0.9171238495753362\n",
      "accuracy:  0.6885516826923077\n",
      "ends\n",
      "eval loss 1.0023894997743459\n",
      "accuracy:  0.6775841346153846\n",
      "ends\n",
      "eval loss 0.9210545328947214\n",
      "accuracy:  0.6881009615384616\n",
      "ends\n",
      "eval loss 1.0513921425892756\n",
      "accuracy:  0.6729266826923077\n",
      "ends\n",
      "eval loss 0.8770467318021334\n",
      "accuracy:  0.6926832932692307\n",
      "ends\n",
      "eval loss 0.9443124486849859\n",
      "accuracy:  0.6859975961538461\n",
      "ends\n",
      "eval loss 0.9714370048963107\n",
      "accuracy:  0.6827674278846154\n",
      "ends\n",
      "eval loss 0.9944236461932843\n",
      "accuracy:  0.6811147836538461\n",
      "ends\n",
      "eval loss 0.9484816606228168\n",
      "accuracy:  0.6850961538461539\n",
      "ends\n",
      "eval loss 0.8946180160229023\n",
      "accuracy:  0.6916316105769231\n",
      "ends\n",
      "eval loss 0.9550573917535635\n",
      "accuracy:  0.6844200721153846\n",
      "ends\n",
      "eval loss 1.0330088092730596\n",
      "accuracy:  0.6756310096153846\n",
      "ends\n",
      "eval loss 1.0647786488899817\n",
      "accuracy:  0.6732271634615384\n",
      "ends\n",
      "eval loss 0.9082795885893015\n",
      "accuracy:  0.6884765625\n",
      "ends\n",
      "eval loss 0.9085447788238525\n",
      "accuracy:  0.6882512019230769\n",
      "ends\n",
      "eval loss 0.9711868029374343\n",
      "accuracy:  0.6829176682692307\n",
      "ends\n",
      "eval loss 0.9374217207615192\n",
      "accuracy:  0.6870492788461539\n",
      "ends\n",
      "eval loss 0.9878831459925725\n",
      "accuracy:  0.6813401442307693\n",
      "ends\n",
      "eval loss 0.8686995047789353\n",
      "accuracy:  0.6932091346153846\n",
      "ends\n",
      "eval loss 0.9303229451179504\n",
      "accuracy:  0.6887019230769231\n",
      "ends\n",
      "eval loss 0.9147364359635574\n",
      "accuracy:  0.6905799278846154\n",
      "ends\n",
      "eval loss 0.9104168506769034\n",
      "accuracy:  0.6889272836538461\n",
      "ends\n",
      "eval loss 0.9228698702958914\n",
      "accuracy:  0.6896784855769231\n",
      "ends\n",
      "eval loss 0.9332743057837853\n",
      "accuracy:  0.6868239182692307\n",
      "ends\n"
     ]
    }
   ],
   "source": [
    "def accuracy(preds, labels):\n",
    "    return (preds == labels).mean()\n",
    "\n",
    "# define evaluation cycle\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "\n",
    "    loss_arr = []\n",
    "    accuracy_arr = []\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        #batch = tuple(t.to(\"cuda\") for t in batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            input_ids = batch['input_ids']\n",
    "            attention_mask = batch['attention_mask']\n",
    "            labels = batch['labels']\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss, logits = outputs[:2]\n",
    "\n",
    "            log = logits.cpu()\n",
    "            log = log.numpy()\n",
    "\n",
    "            preds = np.argmax(log, axis=1)\n",
    "            labels = batch['labels'].cpu().numpy()\n",
    "\n",
    "            loss_arr.append(loss.item())\n",
    "            accuracy_arr.append(accuracy(preds, labels))\n",
    "\n",
    "    model.train()\n",
    "    return np.mean(loss_arr), np.mean(accuracy_arr)\n",
    "\n",
    "# Training loop\n",
    "optimizer.zero_grad()  # Explicitly zero the gradient buffers\n",
    "\n",
    "for epoch in range(60):  # Number of epochs\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "\n",
    "        # print(f\"input_ids size: {input_ids.size()}\")\n",
    "        # print(f\"attention_mask size: {attention_mask.size()}\")\n",
    "        # print(f\"labels size: {labels.size()}\")\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        # print(outputs)\n",
    "        loss = outputs[0]\n",
    "        # print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        logits = outputs[1]\n",
    "        predictions = torch.argmax(logits, dim = -1)\n",
    "        #metric.add_batch(predictions = predictions, references = batch[\"labels\"])\n",
    "\n",
    "    eval_loss, eval_accuracy = evaluate(model)\n",
    "    print(\"eval loss\",eval_loss)\n",
    "    print(\"accuracy: \",eval_accuracy)\n",
    "    print(\"ends\")\n",
    "    #metric.compute()\n",
    "    #print(metric)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    for batch in test_dataloader:\n",
    "        with torch.no_grad():\n",
    "            input_ids = batch['input_ids']\n",
    "            attention_mask = batch['attention_mask']\n",
    "            labels = batch['labels']\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            # Further validation steps if needed\n",
    "\n",
    "    model.train()  # Set the model back to training mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbff754c-3218-4ff7-9f88-a00ccc967c84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myJupyter",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
